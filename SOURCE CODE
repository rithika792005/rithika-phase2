# Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("movie_recommendation_dataset.csv")
# Step 1: Inspect the first few rows of the dataset
print(df.head())

# Step 2: Dataset Information (check data types and null values)
print("\nDataset Info:")
print(df.info())

# Check for missing values
print("\nMissing Values:\n", df.isnull().sum())

# Check for duplicate rows
print("\nDuplicate Rows:", df.duplicated().sum())

# Step 3: Data Cleaning
# Drop duplicate rows
df = df.drop_duplicates()

# Handle missing values (example: filling missing ratings with the mean rating)
df['rating'].fillna(df['rating'].mean(), inplace=True)

# Convert 'release_date' column to datetime format (if applicable)
# Check if 'release_date' column exists before converting
if 'release_date' in df.columns:
    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
else:
    print("Column 'release_date' not found in the DataFrame.")

print("\nDataset after cleaning:")
print(df.head())

plt.figure(figsize=(8, 6))
sns.histplot(df['rating'], bins=20, kde=True, color='blue')
plt.title('Distribution of Movie Ratings')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.show()

# Calculate the top 10 most rated movies
# Assuming 'movie_title' column contains the movie titles
top_rated_movies = df['movie_title'].value_counts().head(10)

plt.figure(figsize=(10, 6))
top_rated_movies.plot(kind='barh', color='green')
plt.title('Top 10 Most Rated Movies')
plt.xlabel('Number of Ratings')
plt.ylabel('Movie Title')
plt.show()

# If your dataset contains genres as one-hot encoded columns (adjust as needed)
genre_columns = df.columns[6:]  # Adjust depending on your column names for genres
genre_counts = df[genre_columns].sum().sort_values(ascending=False)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ... (other parts of your code) ...

# Genre Distribution Analysis (Revised)
if 'genres' in df.columns:
    # Assuming 'genres' column contains a list of genres separated by '|'
    all_genres = []
    for index in df.index:
        genres_list = str(df.loc[index, 'genres']).split('|')  # Split genres
        for genre in genres_list:
            if genre != '' and genre not in all_genres:  # Avoid empty or duplicate entries
                all_genres.append(genre)
    # Count genre occurrences
    genre_counts = {genre: 0 for genre in all_genres}  # Initialize counts
    for index in df.index:
        genres_list = str(df.loc[index, 'genres']).split('|')  # Split genres
        for genre in genres_list:
            if genre != '' and genre in all_genres:  # Only count valid entries
                genre_counts[genre] += 1
    # Sort genres by counts
    genre_counts_sorted = dict(sorted(genre_counts.items(), key=lambda item: item[1], reverse=True))
    # Plot genre distribution
    plt.figure(figsize=(12, 6))  # Adjust figure size
    sns.barplot(x=list(genre_counts_sorted.keys()), y=list(genre_counts_sorted.values()), color='purple')
    plt.title('Genre Distribution')
    plt.xlabel('Genres')
    plt.ylabel('Frequency')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

# Phase 1: Import Libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("movie_recommendation_dataset.csv")

# Clean and prepare
df = df.drop_duplicates()
# Check if 'release_date' column exists before converting
if 'release_date' in df.columns:
    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
else:
    print("Column 'release_date' not found in the DataFrame. Skipping conversion.")

# Check basic info (optional)
print(df.info())

# Phase 2: EDA â€“ Distribution of Ratings per User
# Step 1: Count number of ratings each user has given
user_ratings_count = df['user_id'].value_counts()

# Step 2: Plot distribution of ratings per user
plt.figure(figsize=(8, 6))
sns.histplot(user_ratings_count, bins=30, kde=True, color='orange')
plt.title('Distribution of Ratings Per User')
plt.xlabel('Number of Ratings per User')
plt.ylabel('Frequency')
plt.show()

# Correlation Heatmap (Optional)
# If you have additional numerical columns, such as movie budgets, durations, etc.
# Select only numerical features for correlation analysis
numerical_df = df.select_dtypes(include=['number'])  # Select columns with numeric types

# Calculate the correlation matrix using the numerical features only
correlation_matrix = numerical_df.corr()

# Plot the correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

# Create a user-item matrix with users as rows and movies as columns
user_item_matrix = df.pivot_table(index='user_id', columns='movie_title', values='rating') # Changed 'title' to 'movie_title'

# Fill NaN with 0 (or you can choose to use mean later)
user_item_matrix = user_item_matrix.fillna(0)

# Preview the matrix
user_item_matrix.head()

# Create a user-item matrix with users as rows and movies as columns
user_item_matrix = df.pivot_table(index='user_id', columns='movie_title', values='rating') # Changed 'title' to 'movie_title'

# Fill NaN with 0 (or you can choose to use mean later)
user_item_matrix = user_item_matrix.fillna(0)

# Preview the matrix
user_item_matrix.head()

def get_user_recommendations(user_id, user_item_matrix, similarity_df, num_recommendations=5):
    # Get scores of similar users
    similar_users = similarity_df[user_id].sort_values(ascending=False)[1:]

    # Weighted sum of ratings from similar users
    weighted_ratings = pd.Series(dtype=float)
    for other_user, similarity in similar_users.items():
        user_ratings = user_item_matrix.loc[other_user]
        weighted_ratings = weighted_ratings.add(user_ratings * similarity, fill_value=0)

    # Remove movies already rated by the user
    user_seen_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index
    weighted_ratings = weighted_ratings.drop(labels=user_seen_movies, errors='ignore')

    # Recommend top N movies
    recommendations = weighted_ratings.sort_values(ascending=False).head(num_recommendations)
    return recommendations


recommended_movies = get_user_recommendations(
    user_id=1,
    user_item_matrix=user_item_matrix,
    similarity_df=user_similarity_df,
    num_recommendations=5
)

print("Recommended Movies for User 1:")
print(recommended_movies)


print(df.columns)
['userId', 'movieId', 'rating']
print(df.columns)

milarimport pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
import numpy as np

# Load dataset
df = pd.read_csv("movie_recommendation_dataset.csv")

# Drop duplicates and missing
df.drop_duplicates(inplace=True)
# Replace 'userId' and 'movieId' with actual column names if they are different
df.dropna(subset=['user_id', 'movie_id', 'rating'], inplace=True)  # Assuming column names are 'user_id', 'movie_id'

# Create user-item matrix
user_movie_matrix = df.pivot_table(index='user_id', columns='movie_id', values='rating')  # Updated column names

# Fill NaNs with 0 (or you can use mean if needed)
user_movie_matrix_filled = user_movie_matrix.fillna(0)

# Compute cosine similarity between users
user_similarity = cosine_similarity(user_movie_matrix_filled)
user_similarity_df = pd.DataFrame(user_siity, index=user_movie_matrix.index, columns=user_movie_matrix.index)

print("User-User Similarity Matrix:")
print(user_similarity_df.head())

def recommend_movies(user_id, user_movie_matrix, similarity_df, n_recommendations=5):
    similar_users = similarity_df[user_id].sort_values(ascending=False)[1:]  # Skip self
    weighted_ratings = pd.Series(dtype='float64')

    for other_user, similarity_score in similar_users.items():
        other_user_ratings = user_movie_matrix.loc[other_user]
        weighted_ratings = weighted_ratings.add(other_user_ratings * similarity_score, fill_value=0)

    already_watched = user_movie_matrix.loc[user_id][user_movie_matrix.loc[user_id].notna()].index
    recommendations = weighted_ratings.drop(labels=already_watched).sort_values(ascending=False).head(n_recommendations)

    return recommendations

# Example: Recommend for user with ID 1
recommendations = recommend_movies(1, user_movie_matrix, user_similarity_df)
print("Top movie recommendations for user 1:\n", recommendations)


for user_id in [1, 2, 3]:  # Change user IDs based on your dataset
    print(f"\nTop recommendations for User {user_id}:")
    print(recommend_movies(user_id, user_movie_matrix, user_similarity_df))

# Create the user-movie ratings matrix (if not already created)
user_movie_matrix = df.pivot_table(index='user_id', columns='movie_id', values='rating') # Changed 'userId' to 'user_id' and 'movieId' to 'movie_id'

# Fill NaNs with 0 or use mean/median if preferred
user_movie_matrix_filled = user_movie_matrix.fillna(0)

from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

# Calculate cosine similarity between items (movies)
item_similarity = cosine_similarity(user_movie_matrix_filled.T)

# Convert to a DataFrame
item_similarity_df = pd.DataFrame(item_similarity,
                                   index=user_movie_matrix.columns,
                                   columns=user_movie_matrix.columns)
def recommend_similar_movies(movie_id, similarity_df, n_recommendations=5):
    if movie_id not in similarity_df.columns:
        return f"Movie ID {movie_id} not found in similarity matrix."

    # Get similar movies (excluding the movie itself)
    similar_scores = similarity_df[movie_id].sort_values(ascending=False)[1:n_recommendations+1]
    return similar_scores

def recommend_similar_movies(movie_id, similarity_df, n_recommendations=5):
    if movie_id not in similarity_df.columns:
        return f"Movie ID {movie_id} not found in similarity matrix."

    # Get similar movies (excluding the movie itself)
    similar_scores = similarity_df[movie_id].sort_values(ascending=False)[1:n_recommendations+1]
    return similar_scores
